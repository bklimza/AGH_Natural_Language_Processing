{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e14215",
   "metadata": {
    "id": "61e14215"
   },
   "source": [
    "# Natural Language Processing - lab 6 (Language modelling)\n",
    "\n",
    "Bartosz Klimza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f7409",
   "metadata": {
    "id": "8f8f7409"
   },
   "source": [
    "# Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rLIJ0gev8O79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLIJ0gev8O79",
    "outputId": "db445af2-6bed-4218-f413-793a656256dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 25.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 42.9 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 503 kB/s \n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 38.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 43.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4cf08b0",
   "metadata": {
    "id": "c4cf08b0"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HQdZYWTg2vZL",
   "metadata": {
    "id": "HQdZYWTg2vZL"
   },
   "source": [
    "# 1. Read the documentation of Language modelling in the Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "mz_NLZ8U21Up",
   "metadata": {
    "id": "mz_NLZ8U21Up"
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/task_summary#language-modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73XtKnKf8kDq",
   "metadata": {
    "id": "73XtKnKf8kDq"
   },
   "source": [
    "# 2. Download three Polish models from the Huggingface repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "siXkM53G801a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "siXkM53G801a",
    "outputId": "f864988b-c905-45a8-b450-f277f565a215"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dkleczek/bert-base-polish-uncased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer_1 = AutoTokenizer.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")\n",
    "model_1 = AutoModelForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")\n",
    "\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(\"Geotrend/distilbert-base-pl-cased\")\n",
    "model_2 = AutoModelForMaskedLM.from_pretrained(\"Geotrend/distilbert-base-pl-cased\")\n",
    "\n",
    "tokenizer_3 = AutoTokenizer.from_pretrained(\"Geotrend/bert-base-pl-cased\")\n",
    "model_3 = AutoModelForMaskedLM.from_pretrained(\"Geotrend/bert-base-pl-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8l6_R8sM1pPb",
   "metadata": {
    "id": "8l6_R8sM1pPb"
   },
   "source": [
    "# 3. Produce the predictions for the following sentences (use each model and check 5 predictions):\n",
    "\n",
    "* (M) Warszawa to największe [MASK].\n",
    "* (D) Te zabawki należą do [MASK].\n",
    "* (C) Policjant przygląda się [MASK].\n",
    "* (B) Na środku skrzyżowania widać [MASK].\n",
    "* (N) Właściciel samochodu widział złodzieja z [MASK].\n",
    "* (Ms) Prezydent z premierem rozmawiali wczoraj o [MASK].\n",
    "* (W) Witaj drogi [MASK]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "CcqXoslmu283",
   "metadata": {
    "id": "CcqXoslmu283"
   },
   "outputs": [],
   "source": [
    "# This method was described in a documentation from the first point\n",
    "def make_prediction(tokenizer, model, sequence):\n",
    "  sequence = sequence.replace(\"[MASK]\", tokenizer.mask_token)\n",
    "  inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "  mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "  token_logits = model(**inputs).logits\n",
    "  mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "  top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "  return_list = []\n",
    "  for token in top_5_tokens:\n",
    "    return_list.append(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))\n",
    "  return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcdOnmT9zs_k",
   "metadata": {
    "id": "bcdOnmT9zs_k"
   },
   "outputs": [],
   "source": [
    "ex_3_sequences = [\"Warszawa to największe [MASK].\",\n",
    "                  \"Te zabawki należą do [MASK].\",\n",
    "                  \"Policjant przygląda się [MASK].\",\n",
    "                  \"Na środku skrzyżowania widać [MASK].\",\n",
    "                  \"Właściciel samochodu widział złodzieja z [MASK].\",\n",
    "                  \"Prezydent z premierem rozmawiali wczoraj o [MASK].\",\n",
    "                  \"Witaj, drogi [MASK].\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "rYkL6e8-9_qO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYkL6e8-9_qO",
    "outputId": "051e8ab9-23a6-4e56-aadc-494a4bc89521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dkleczek/bert-base-polish-uncased-v1\n",
      "['Warszawa to największe miasto.', 'Warszawa to największe miejsce.', 'Warszawa to największe lotnisko.', 'Warszawa to największe centrum.', 'Warszawa to największe miasta.']\n",
      "['Te zabawki należą do mnie.', 'Te zabawki należą do ciebie.', 'Te zabawki należą do niego.', 'Te zabawki należą do nas.', 'Te zabawki należą do pana.']\n",
      "['Policjant przygląda się temu.', 'Policjant przygląda się mu.', 'Policjant przygląda się im.', 'Policjant przygląda się nam.', 'Policjant przygląda się jej.']\n",
      "['Na środku skrzyżowania widać dym.', 'Na środku skrzyżowania widać wszystko.', 'Na środku skrzyżowania widać ulice.', 'Na środku skrzyżowania widać ruch.', 'Na środku skrzyżowania widać samochod.']\n",
      "['Właściciel samochodu widział złodzieja z tyłu.', 'Właściciel samochodu widział złodzieja z bliska.', 'Właściciel samochodu widział złodzieja z samochodu.', 'Właściciel samochodu widział złodzieja z kamera.', 'Właściciel samochodu widział złodzieja z parkingu.']\n",
      "['Prezydent z premierem rozmawiali wczoraj o tym.', 'Prezydent z premierem rozmawiali wczoraj o ataku.', 'Prezydent z premierem rozmawiali wczoraj o panu.', 'Prezydent z premierem rozmawiali wczoraj o tobie.', 'Prezydent z premierem rozmawiali wczoraj o zamachu.']\n",
      "['Witaj, drogi chłopcze.', 'Witaj, drogi przyjacielu.', 'Witaj, drogi bracie.', 'Witaj, drogi panie.', 'Witaj, drogi synu.']\n",
      "\n",
      "\n",
      "Geotrend/distilbert-base-pl-cased\n",
      "['Warszawa to największe miasto.', 'Warszawa to największe miasta.', 'Warszawa to największe Miasto.', 'Warszawa to największe centrum.', 'Warszawa to największe dzielnicy.']\n",
      "['Te zabawki należą do klasyfikacji.', 'Te zabawki należą do gry.', 'Te zabawki należą do rodziny.', 'Te zabawki należą do grupy.', 'Te zabawki należą do zespołu.']\n",
      "['Policjant przygląda się przeciwko.', 'Policjant przygląda się LGBT.', 'Policjant przygląda się walki.', 'Policjant przygląda się nie.', 'Policjant przygląda się ludzi.']\n",
      "['Na środku skrzyżowania widać wody.', 'Na środku skrzyżowania widać ##ały.', 'Na środku skrzyżowania widać miejsca.', 'Na środku skrzyżowania widać brak.', 'Na środku skrzyżowania widać ##ły.']\n",
      "['Właściciel samochodu widział złodzieja z Warszawy.', 'Właściciel samochodu widział złodzieja z pochodzenia.', 'Właściciel samochodu widział złodzieja z Niemiec.', 'Właściciel samochodu widział złodzieja z Łodzi.', 'Właściciel samochodu widział złodzieja z Rosji.']\n",
      "['Prezydent z premierem rozmawiali wczoraj o prezydenta.', 'Prezydent z premierem rozmawiali wczoraj o referendum.', 'Prezydent z premierem rozmawiali wczoraj o władze.', 'Prezydent z premierem rozmawiali wczoraj o premiera.', 'Prezydent z premierem rozmawiali wczoraj o LGBT.']\n",
      "['Witaj, drogi itd.', 'Witaj, drogi drogi.', 'Witaj, drogi polskiej.', 'Witaj, drogi Europy.', 'Witaj, drogi narodowej.']\n",
      "\n",
      "\n",
      "Geotrend/bert-base-pl-cased\n",
      "['Warszawa to największe miasto.', 'Warszawa to największe miasta.', 'Warszawa to największe woj.', 'Warszawa to największe Warszawa.', 'Warszawa to największe miast.']\n",
      "['Te zabawki należą do tzw.', 'Te zabawki należą do pt.', 'Te zabawki należą do pl.', 'Te zabawki należą do odc.', 'Te zabawki należą do ok.']\n",
      "['Policjant przygląda się go.', 'Policjant przygląda się ok.', 'Policjant przygląda się się.', 'Policjant przygląda się pt.', 'Policjant przygląda się nie.']\n",
      "['Na środku skrzyżowania widać św.', 'Na środku skrzyżowania widać ok.', 'Na środku skrzyżowania widać obraz.', 'Na środku skrzyżowania widać rok.', 'Na środku skrzyżowania widać kościół.']\n",
      "['Właściciel samochodu widział złodzieja z pt.', 'Właściciel samochodu widział złodzieja z tzw.', 'Właściciel samochodu widział złodzieja z ul.', 'Właściciel samochodu widział złodzieja z woj.', 'Właściciel samochodu widział złodzieja z kościoła.']\n",
      "['Prezydent z premierem rozmawiali wczoraj o północy.', 'Prezydent z premierem rozmawiali wczoraj o tym.', 'Prezydent z premierem rozmawiali wczoraj o nim.', 'Prezydent z premierem rozmawiali wczoraj o co.', 'Prezydent z premierem rozmawiali wczoraj o św.']\n",
      "['Witaj, drogi ##arz.', 'Witaj, drogi ##sz.', 'Witaj, drogi ##er.', 'Witaj, drogi ##ew.', 'Witaj, drogi ##erk.']\n"
     ]
    }
   ],
   "source": [
    "print(\"dkleczek/bert-base-polish-uncased-v1\")\n",
    "for s in ex_3_sequences:\n",
    "  print(make_prediction(tokenizer_1, model_1, s))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Geotrend/distilbert-base-pl-cased\")\n",
    "\n",
    "for s in ex_3_sequences:\n",
    "  print(make_prediction(tokenizer_2, model_2, s))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Geotrend/bert-base-pl-cased\")\n",
    "\n",
    "for s in ex_3_sequences:\n",
    "  print(make_prediction(tokenizer_3, model_3, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dl8GGpF12Y7O",
   "metadata": {
    "id": "Dl8GGpF12Y7O"
   },
   "source": [
    "# 4. Check the model predictions for the following sentences (using each model):\n",
    "\n",
    "* Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie [MASK].\n",
    "* Gdybym wiedziała wtedy dokładnie to, co wiem teraz, to bym się nie [MASK]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "zkiEJjMY1Z97",
   "metadata": {
    "id": "zkiEJjMY1Z97"
   },
   "outputs": [],
   "source": [
    "ex_4_sequences = [\"Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie [MASK].\",\n",
    "                  \"Gdybym wiedziała wtedy dokładnie to, co wiem teraz, to bym się nie [MASK].\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "KFpentYm3bxk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFpentYm3bxk",
    "outputId": "3694bb79-5366-46b4-829d-8925b8a61c50",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dkleczek/bert-base-polish-uncased-v1\n",
      "['Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie dowiedział.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie martwił.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie zgodził.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie przyznał.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie przejmował.']\n",
      "['Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie dowiedziała.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zgodziła.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie przyznała.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie zabiła.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie poddała.']\n",
      "\n",
      "\n",
      "Geotrend/distilbert-base-pl-cased\n",
      "['Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie było.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie stanie.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie udało.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie tylko.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie odbył.']\n",
      "['Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie było.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie udało.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie stanie.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie tylko.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie ma.']\n",
      "\n",
      "\n",
      "Geotrend/bert-base-pl-cased\n",
      "['Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie ##wiedział.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie było.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie stało.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie ##dził.', 'Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie ##dzi.']\n",
      "['Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie było.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie ##wia.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie stało.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie ##wiedział.', 'Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie ##czyła.']\n"
     ]
    }
   ],
   "source": [
    "print(\"dkleczek/bert-base-polish-uncased-v1\")\n",
    "for s in ex_4_sequences:\n",
    "  print(make_prediction(tokenizer_1, model_1, s))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Geotrend/distilbert-base-pl-cased\")\n",
    "\n",
    "for s in ex_4_sequences:\n",
    "  print(make_prediction(tokenizer_2, model_2, s))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Geotrend/bert-base-pl-cased\")\n",
    "\n",
    "for s in ex_4_sequences:\n",
    "  print(make_prediction(tokenizer_3, model_3, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0X4Gqsf31pm",
   "metadata": {
    "id": "b0X4Gqsf31pm"
   },
   "source": [
    "# 5. Check the model predictions for the following sentences:\n",
    "\n",
    "* [MASK] wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\n",
    "* W wakacje odwiedziłem [MASK], który jest stolicą Islandii.\n",
    "* Informatyka na [MASK] należy do najlepszych kierunków w Polsce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "KkEoKCQO4mOz",
   "metadata": {
    "id": "KkEoKCQO4mOz"
   },
   "outputs": [],
   "source": [
    "ex_5_sequences = [\n",
    "  \"[MASK] wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.\",\n",
    "  \"W wakacje odwiedziłem [MASK], który jest stolicą Islandii.\",\n",
    "  \"Informatyka na [MASK] należy do najlepszych kierunków w Polsce.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "oLLe9rny47UQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLLe9rny47UQ",
    "outputId": "d5752715-c130-4935-994d-7f4b9c690a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dkleczek/bert-base-polish-uncased-v1\n",
      "['woda wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'ciało wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'nie wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'lod wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'powietrze wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.']\n",
      "['W wakacje odwiedziłem zamek, który jest stolicą Islandii.', 'W wakacje odwiedziłem kraj, który jest stolicą Islandii.', 'W wakacje odwiedziłem sztokholm, który jest stolicą Islandii.', 'W wakacje odwiedziłem park, który jest stolicą Islandii.', 'W wakacje odwiedziłem region, który jest stolicą Islandii.']\n",
      "['Informatyka na uniwersytecie należy do najlepszych kierunków w Polsce.', 'Informatyka na swiecie należy do najlepszych kierunków w Polsce.', 'Informatyka na uczelni należy do najlepszych kierunków w Polsce.', 'Informatyka na uczelniach należy do najlepszych kierunków w Polsce.', 'Informatyka na ukrainie należy do najlepszych kierunków w Polsce.']\n",
      "\n",
      "\n",
      "Geotrend/distilbert-base-pl-cased\n",
      "['We wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'Na wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'we wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'Zmarł wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'Od wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.']\n",
      "['W wakacje odwiedziłem kraju, który jest stolicą Islandii.', 'W wakacje odwiedziłem pochodzi, który jest stolicą Islandii.', 'W wakacje odwiedziłem flag, który jest stolicą Islandii.', 'W wakacje odwiedziłem wody, który jest stolicą Islandii.', 'W wakacje odwiedziłem referendum, który jest stolicą Islandii.']\n",
      "['Informatyka na stacji należy do najlepszych kierunków w Polsce.', 'Informatyka na Uniwersytecie należy do najlepszych kierunków w Polsce.', 'Informatyka na Ziemi należy do najlepszych kierunków w Polsce.', 'Informatyka na terenie należy do najlepszych kierunków w Polsce.', 'Informatyka na ulicy należy do najlepszych kierunków w Polsce.']\n",
      "\n",
      "\n",
      "Geotrend/bert-base-pl-cased\n",
      "['Jego wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'Za wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'Po wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'Nie wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.', 'Ich wrze w temperaturze 100 stopni, a zamarza w temeraturze 0 stopni Celsjusza.']\n",
      "['W wakacje odwiedziłem Island, który jest stolicą Islandii.', 'W wakacje odwiedziłem Reykjavík, który jest stolicą Islandii.', 'W wakacje odwiedziłem Porto, który jest stolicą Islandii.', 'W wakacje odwiedziłem miasto, który jest stolicą Islandii.', 'W wakacje odwiedziłem Port, który jest stolicą Islandii.']\n",
      "['Informatyka na uczelni należy do najlepszych kierunków w Polsce.', 'Informatyka na rynku należy do najlepszych kierunków w Polsce.', 'Informatyka na internet należy do najlepszych kierunków w Polsce.', 'Informatyka na świecie należy do najlepszych kierunków w Polsce.', 'Informatyka na terenie należy do najlepszych kierunków w Polsce.']\n"
     ]
    }
   ],
   "source": [
    "print(\"dkleczek/bert-base-polish-uncased-v1\")\n",
    "for s in ex_5_sequences:\n",
    "  print(make_prediction(tokenizer_1, model_1, s))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Geotrend/distilbert-base-pl-cased\")\n",
    "\n",
    "for s in ex_5_sequences:\n",
    "  print(make_prediction(tokenizer_2, model_2, s))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Geotrend/bert-base-pl-cased\")\n",
    "\n",
    "for s in ex_5_sequences:\n",
    "  print(make_prediction(tokenizer_3, model_3, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plDPgoeN5XJJ",
   "metadata": {
    "id": "plDPgoeN5XJJ"
   },
   "source": [
    "# 6. If you want to use causal language models such as PapuGaPT2 or plT5, you should change the last three examples to accomodate for the fact, that these models are better suited for causal language modelling.\n",
    "\n",
    "I  used neither PapuGaPT2 nor plT5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HMgK5rKH58mz",
   "metadata": {
    "id": "HMgK5rKH58mz"
   },
   "source": [
    "# 7. Answer the following questions:\n",
    "\n",
    "* Which of the models produced the best results?\n",
    "\n",
    "Moim zdaniem najlepiej poradził sobie model dkleczek/bert-base-polish-uncased-v1.\n",
    "\n",
    "* Was any of the models able to capture Polish grammar?\n",
    "\n",
    "Model_1 i model_2 poradziły sobie całkiem dobrze, jednak mimo wszystko pojawiały się błędy. Model_3 wypadł najgorzej, co widać szczególnie w przykładzie 7 w zadaniu 3.\n",
    "\n",
    "* Was any of the models able to capture long-distant relationships between the words?\n",
    "\n",
    "Można uznać, że model dkleczek/bert-base-polish-uncased-v1 jest w stanie dostrzegać takie zależności.\n",
    "\n",
    "* Was any of the models able to capture world knowledge?\n",
    "\n",
    "Ciężko powiedzieć, Geotrend/bert-base-pl-cased odgadł stolicę Islandii, ale dkleczek/bert-base-polish-uncased-v1 wiedział co wrze w 100 stopniach i zamarza w 0.\n",
    "\n",
    "* What are the most striking errors made by the models?\n",
    "\n",
    "  * Witaj, drogi ##arz. (Zadanie 3, model_3)\n",
    "  * W wakacje odwiedziłem sztokholm, który jest stolicą Islandii. (Zadanie 5, model_1)\n",
    "  * Informatyka na ulicy należy do najlepszych kierunków w Polsce. (Zadanie 5, model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52133baf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PJN_lab_6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
